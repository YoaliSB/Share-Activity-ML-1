# Share-Activity-ML-1
Explicación de método de Newton y BFGS para optimización en ML

Link al video: https://youtu.be/h7iBOGRUN_s

Referencias: 

Becker, S., & Le Cunn, Y. (1988, September). Improving the Convergence of Back-Propagation Learning with Second-Order Methods [PDF]. Toronto: Department of Computer Science, University of Toronto.

Ng, A. (n.d.). CS229 Lectures [PDF].

Nykamp DQ, “Introduction to Taylor's theorem for multivariable functions.” From Math Insight. http://mathinsight.org/taylors_theorem_multivariable_introduction

Toussaint, M. (n.d.). Second Order Optimization Methods [PPT]. Stuttgart: Universität Stuttgart.

Broyden–Fletcher–Goldfarb–Shanno algorithm. (2018, August 15). Retrieved September 13, 2018, from https://en.wikipedia.org/wiki/Broyden–Fletcher–Goldfarb–Shanno_algorithm
